{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cba25221-37e0-4441-d633-95bc62bf3518"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150,150,3),\n",
        "                                include_top = False,\n",
        "                                weights = None) # Your Code Here\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-04 19:54:08--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 2404:6800:4008:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   113MB/s    in 0.7s    \n",
            "\n",
            "2019-10-04 19:54:14 (113 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1004 19:54:16.307094 140030958626688 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8747d0ac-0fb8-4030-a804-346125be36cf"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')# Your Code Here)\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output# Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b580701-4e99-4591-86a6-1ca38b7829b2"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation = 'relu')(x)# Your Code Here)(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)# Your Code Here)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation = 'sigmoid')(x)# Your Code Here)(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x)# Your Code Here, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy',# Your Code Here, \n",
        "              metrics = ['acc']) # Your Code Here)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1004 19:59:02.458616 140030958626688 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "fcbe925d-2b89-465f-dfea-95fe9b439f55"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-04 19:59:07--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  78.5MB/s    in 1.8s    \n",
            "\n",
            "2019-10-04 19:59:09 (78.5 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-10-04 19:59:10--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-10-04 19:59:11 (125 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e957a3cc-9fb0-40de-982e-9f6ccfc1afe1"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "92eaa8fa-d910-401f-e212-574569450400"
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)# Your Code Here)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )# Your Code Here )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150)) # Your Code Here)     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150)) # Your Code Here)\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d331558-686a-43df-8e42-a04e77f7c952"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback() # Your Code Here\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 1,\n",
        "            callbacks=[callbacks])# Your Code Here)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.0945 - acc: 0.9645 - val_loss: 0.0284 - val_acc: 0.9919\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 31s 308ms/step - loss: 0.0622 - acc: 0.9747 - val_loss: 0.0491 - val_acc: 0.9879\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.0390 - acc: 0.9869 - val_loss: 0.0772 - val_acc: 0.9838\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0393 - acc: 0.9852 - val_loss: 0.0663 - val_acc: 0.9879\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0380 - acc: 0.9884 - val_loss: 0.0742 - val_acc: 0.9919\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0247 - acc: 0.9893 - val_loss: 0.5006 - val_acc: 0.9504\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0315 - acc: 0.9894 - val_loss: 0.2325 - val_acc: 0.9605\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0345 - acc: 0.9899 - val_loss: 0.1144 - val_acc: 0.9838\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 30s 296ms/step - loss: 0.0242 - acc: 0.9909 - val_loss: 0.1748 - val_acc: 0.9737\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0247 - acc: 0.9913 - val_loss: 0.0855 - val_acc: 0.9919\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0146 - acc: 0.9950 - val_loss: 0.3042 - val_acc: 0.9686\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0238 - acc: 0.9924 - val_loss: 0.2126 - val_acc: 0.9737\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0293 - acc: 0.9914 - val_loss: 0.0766 - val_acc: 0.9919\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0256 - acc: 0.9934 - val_loss: 0.0060 - val_acc: 0.9960\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.0345 - acc: 0.9914 - val_loss: 0.0382 - val_acc: 0.9919\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 30s 297ms/step - loss: 0.0165 - acc: 0.9954 - val_loss: 0.1629 - val_acc: 0.9798\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0176 - acc: 0.9944 - val_loss: 0.0920 - val_acc: 0.9919\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0252 - acc: 0.9965 - val_loss: 0.3724 - val_acc: 0.9575\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 30s 296ms/step - loss: 0.0208 - acc: 0.9950 - val_loss: 0.1454 - val_acc: 0.9889\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0137 - acc: 0.9959 - val_loss: 0.5682 - val_acc: 0.9565\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0106 - acc: 0.9970 - val_loss: 0.1727 - val_acc: 0.9808\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.4349 - val_acc: 0.9656\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0199 - acc: 0.9934 - val_loss: 0.2154 - val_acc: 0.9808\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0332 - acc: 0.9919 - val_loss: 0.2721 - val_acc: 0.9727\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0243 - acc: 0.9934 - val_loss: 0.6697 - val_acc: 0.9423\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0177 - acc: 0.9959 - val_loss: 0.4315 - val_acc: 0.9646\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0110 - acc: 0.9975 - val_loss: 0.3113 - val_acc: 0.9696\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.0175 - acc: 0.9950 - val_loss: 0.6326 - val_acc: 0.9565\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.0108 - acc: 0.9970 - val_loss: 0.6978 - val_acc: 0.9504\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0229 - acc: 0.9954 - val_loss: 0.7258 - val_acc: 0.9514\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0114 - acc: 0.9980 - val_loss: 0.4668 - val_acc: 0.9646\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0137 - acc: 0.9970 - val_loss: 0.3777 - val_acc: 0.9676\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0106 - acc: 0.9970 - val_loss: 0.9220 - val_acc: 0.9464\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0072 - acc: 0.9970 - val_loss: 0.9769 - val_acc: 0.9443\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0249 - acc: 0.9939 - val_loss: 0.5596 - val_acc: 0.9605\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0187 - acc: 0.9970 - val_loss: 0.7603 - val_acc: 0.9565\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0284 - acc: 0.9929 - val_loss: 0.7841 - val_acc: 0.9514\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0270 - acc: 0.9934 - val_loss: 0.9667 - val_acc: 0.9494\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 1.2362 - val_acc: 0.9474\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0150 - acc: 0.9970 - val_loss: 1.0458 - val_acc: 0.9453\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.0020 - acc: 0.9985 - val_loss: 0.7364 - val_acc: 0.9534\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.0045 - acc: 0.9980 - val_loss: 1.3067 - val_acc: 0.9464\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0289 - acc: 0.9944 - val_loss: 0.5401 - val_acc: 0.9575\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0122 - acc: 0.9965 - val_loss: 0.4750 - val_acc: 0.9696\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.8089 - val_acc: 0.9534\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0153 - acc: 0.9959 - val_loss: 0.8153 - val_acc: 0.9524\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0096 - acc: 0.9975 - val_loss: 0.5008 - val_acc: 0.9717\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0161 - acc: 0.9975 - val_loss: 0.6267 - val_acc: 0.9605\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0122 - acc: 0.9955 - val_loss: 0.8342 - val_acc: 0.9534\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0047 - acc: 0.9980 - val_loss: 1.4929 - val_acc: 0.9403\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0094 - acc: 0.9990 - val_loss: 1.0016 - val_acc: 0.9443\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.9348 - val_acc: 0.9443\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0141 - acc: 0.9965 - val_loss: 0.2483 - val_acc: 0.9889\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.0091 - acc: 0.9959 - val_loss: 0.8436 - val_acc: 0.9534\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.0244 - acc: 0.9965 - val_loss: 0.6722 - val_acc: 0.9514\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0067 - acc: 0.9985 - val_loss: 1.0462 - val_acc: 0.9433\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0153 - acc: 0.9965 - val_loss: 1.0707 - val_acc: 0.9443\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.7602 - val_acc: 0.9504\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0399 - acc: 0.9954 - val_loss: 1.2232 - val_acc: 0.9464\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0074 - acc: 0.9990 - val_loss: 1.2720 - val_acc: 0.9464\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0115 - acc: 0.9960 - val_loss: 1.2299 - val_acc: 0.9474\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0169 - acc: 0.9965 - val_loss: 1.7959 - val_acc: 0.9332\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0091 - acc: 0.9980 - val_loss: 0.7699 - val_acc: 0.9504\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0094 - acc: 0.9975 - val_loss: 1.3170 - val_acc: 0.9443\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0299 - acc: 0.9955 - val_loss: 0.9136 - val_acc: 0.9453\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0225 - acc: 0.9970 - val_loss: 1.5559 - val_acc: 0.9393\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.0185 - acc: 0.9949 - val_loss: 1.2177 - val_acc: 0.9474\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.0129 - acc: 0.9965 - val_loss: 1.6596 - val_acc: 0.9372\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0101 - acc: 0.9970 - val_loss: 1.6213 - val_acc: 0.9352\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0080 - acc: 0.9965 - val_loss: 1.4457 - val_acc: 0.9423\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0214 - acc: 0.9965 - val_loss: 1.2508 - val_acc: 0.9494\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0108 - acc: 0.9980 - val_loss: 1.1779 - val_acc: 0.9443\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0149 - acc: 0.9975 - val_loss: 1.2408 - val_acc: 0.9453\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.7289 - val_acc: 0.9605\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0161 - acc: 0.9959 - val_loss: 0.9494 - val_acc: 0.9514\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0155 - acc: 0.9959 - val_loss: 1.2237 - val_acc: 0.9433\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0040 - acc: 0.9980 - val_loss: 1.5499 - val_acc: 0.9413\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0289 - acc: 0.9959 - val_loss: 1.5010 - val_acc: 0.9413\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.8701 - val_acc: 0.9514\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 31s 305ms/step - loss: 0.0147 - acc: 0.9975 - val_loss: 1.0460 - val_acc: 0.9433\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.0023 - acc: 0.9980 - val_loss: 1.2163 - val_acc: 0.9464\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0157 - acc: 0.9965 - val_loss: 0.7107 - val_acc: 0.9615\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0063 - acc: 0.9990 - val_loss: 1.0749 - val_acc: 0.9474\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0107 - acc: 0.9959 - val_loss: 1.0884 - val_acc: 0.9443\n",
            "Epoch 85/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9995\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 1.1881 - val_acc: 0.9443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "350fa97e-f9f2-4708-d050-3f919c7394ed"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQv6xhgTRSzoG2NMFLGgb4wxUeT/AejKJd9IwQ3/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOK1EUg6hiwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}